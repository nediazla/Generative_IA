# **Referencias y Fuentes Normativas**

## **1. Fuentes legales y regulatorias**

**Unión Europea**

- Parlamento Europeo y Consejo de la Unión Europea. _Reglamento de Inteligencia Artificial (AI Act)_. Bruselas, 2024.  
    (Regula el uso, clasificación de riesgos y supervisión de sistemas de IA en territorio europeo).
- Parlamento Europeo y Consejo de la Unión Europea. _Reglamento (UE) 2016/679 — Reglamento General de Protección de Datos (RGPD)_.  
    Diario Oficial de la Unión Europea, 2016.
- Comisión Europea. _Ethics Guidelines for Trustworthy Artificial Intelligence_. High-Level Expert Group on AI (HLEG), 2019.
- European Data Protection Board (EDPB). _Guidelines on Data Protection and Artificial Intelligence_, 2023.

**Estados Unidos**

- _Blueprint for an AI Bill of Rights_. The White House, Office of Science and Technology Policy (OSTP), 2022.
- _National Institute of Standards and Technology (NIST) — AI Risk Management Framework (AI RMF 1.0)_, 2023.
- _California Consumer Privacy Act (CCPA)_, California Legislative Information, 2020.

**Organismos internacionales**

- UNESCO. _Recommendation on the Ethics of Artificial Intelligence_, 2021.
- OECD. _OECD Principles on Artificial Intelligence_, 2019.
- Council of Europe. _Framework Convention on Artificial Intelligence, Human Rights, Democracy and the Rule of Law_, 2024.
- ONU. _Resolution A/RES/78/249 — Seizing the Opportunities of Safe, Secure and Trustworthy Artificial Intelligence Systems for Sustainable Development_, 2024.

---

## **2. Fuentes técnicas y científicas**

**Aprendizaje automático y modelos generativos**

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). _Deep Learning_. MIT Press.  
    (Referencia fundamental sobre redes neuronales, autoencoders, y GANs).
- Vaswani, A. et al. (2017). _Attention Is All You Need_. Advances in Neural Information Processing Systems (NeurIPS).  
    (Artículo seminal que introduce la arquitectura Transformer).
- Ho, J., Jain, A., & Abbeel, P. (2020). _Denoising Diffusion Probabilistic Models_. NeurIPS.
- Brown, T. et al. (2020). _Language Models Are Few-Shot Learners (GPT-3)_. OpenAI.
- Radford, A. et al. (2021). _Learning Transferable Visual Models From Natural Language Supervision (CLIP)_. OpenAI.
- Rombach, R. et al. (2022). _High-Resolution Image Synthesis with Latent Diffusion Models (Stable Diffusion)_. CVPR.

**Control, evaluación y fiabilidad**

- Hendrycks, D. et al. (2023). _Aligning AI With Human Values_. Stanford University.
- Mitchell, M. (2023). _Artificial Intelligence: A Guide for Thinking Humans_. Penguin Books.
- Bender, E., Gebru, T. et al. (2021). _On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?_. FAccT Conference.
- Bommasani, R. et al. (2022). _The Foundation Model Review_. Stanford Center for Research on Foundation Models (CRFM).    

---

## **3. Fuentes éticas, filosóficas y sociales**

**Ética, sesgo y gobernanza**

- Floridi, L. (2019). _The Logic of Information: A Theory of Philosophy as Conceptual Design_. Oxford University Press.
- Mittelstadt, B. (2019). _Principles Alone Cannot Guarantee Ethical AI_. Nature Machine Intelligence.
- Crawford, K. (2021). _Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence_. Yale University Press.
- Jobin, A., Ienca, M., & Vayena, E. (2019). _The Global Landscape of AI Ethics Guidelines_. Nature Machine Intelligence.
- Whittlestone, J., Nyrup, R., Alexandrova, A., & Cave, S. (2019). _The Role and Limits of Principles in AI Ethics_. ACM Journal on Ethics and Technology.
- Hagendorff, T. (2020). _The Ethics of AI Ethics: An Evaluation of Guidelines_. Minds and Machines.

**Privacidad y derechos digitales**

- Zuboff, S. (2019). _The Age of Surveillance Capitalism_. PublicAffairs.
- Solove, D. J. (2021). _Privacy Law Fundamentals_. IAPP Press.
- Nissenbaum, H. (2010). _Privacy in Context: Technology, Policy, and the Integrity of Social Life_. Stanford Law Books.
- Rocher, L., Hendrickx, J. M., & de Montjoye, Y. (2019). _Estimating the Success of Re-Identifications in Incomplete Datasets Using Generative Models_. Nature Communications.

**Responsabilidad y gobernanza internacional**

- Calo, R. (2015). _Robotics and the Lessons of Cyberlaw_. California Law Review.
- Yeung, K. (2020). _A Study of Accountability in the Age of Artificial Intelligence_. Oxford Internet Institute.
- Cath, C. (2018). _Governing Artificial Intelligence: Ethical, Legal and Technical Opportunities and Challenges_. Philosophical Transactions of the Royal Society A.   

---

## **4. Referencias complementarias (uso en docencia y certificación)**

- IEEE. _Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems_, 2022.
- WEF (World Economic Forum). _AI Governance: A Holistic Framework for the Responsible Use of Artificial Intelligence in Organizations_, 2023.
- ISO/IEC. _Standard 42001: Artificial Intelligence Management System (AIMS)_, 2023.
- OECD. _AI Policy Observatory Database_. (Actualizada continuamente, acceso en línea: [https://oecd.ai](https://oecd.ai)).