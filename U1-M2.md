# **Módulo 2: Procesos**

## **Objetivos del módulo**

Al finalizar este módulo, el estudiante será capaz de:

1. Comprender los principales **procesos y modelos** que hacen posible la inteligencia artificial moderna.
2. Diferenciar entre los tipos de modelos (texto, imagen, lenguaje, difusión, etc.) y su estructura interna.
3. Explicar cómo funcionan arquitecturas avanzadas como los **Transformers**, **Autoencodificadores Variacionales**, **GANs** y **Redes Convolucionales**.
4. Describir las fases del **entrenamiento de modelos** de IA y su impacto en la calidad de los resultados.

---

## **Términos clave**

- Modelo de texto
- Modelo de imagen
- Modelo de lenguaje grande (LLM)
- Difusión (Diffusion Model)
- Transformer
- Autoencodificador Variacional (VAE)
- Red Generativa Antagónica (GAN)
- Red Neuronal Convolucional (CNN)
- Dataset
- Entrenamiento
- Inferencia
- Tokenización
- Parámetros / Pesos

---

## **1. Modelos de texto**

Los **modelos de texto** son sistemas diseñados para **comprender y generar lenguaje escrito**.  
Utilizan aprendizaje profundo y grandes corpus de texto para aprender el contexto, la gramática y las relaciones entre palabras.

**Ejemplos:**

- ChatGPT (OpenAI)
- Gemini (Google DeepMind)
- Claude (Anthropic)
- LLaMA (Meta)

**Funcionamiento básico:**

1. El texto de entrada se divide en **tokens** (unidades como palabras o subpalabras).
2. El modelo predice el siguiente token más probable según el contexto.
3. Repite este proceso hasta formar una oración completa o cumplir la instrucción.

**Aplicaciones:**

- Asistentes conversacionales.
- Traducción automática.
- Resumen de documentos.
- Generación de código o contenido educativo.

---

## **2. Modelos de imagen**

Los **modelos de imagen** son redes neuronales diseñadas para **interpretar, clasificar o generar imágenes**.  
Pueden funcionar en dos direcciones:

- **Discriminativos:** reconocen objetos, rostros o patrones.
- **Generativos:** crean imágenes nuevas basadas en descripciones o estilos.

**Ejemplos:**

- DALL·E, Midjourney, Stable Diffusion (generación de imágenes).
- ResNet, VGG, Inception (clasificación de imágenes).

**Procesos básicos:**

- Análisis de píxeles o regiones.
- Identificación de características visuales (bordes, colores, formas).
- Generación de nuevas combinaciones visuales basadas en aprendizaje previo.

**Aplicaciones:**

- Arte digital y diseño gráfico.
- Diagnóstico médico por imagen.
- Reconocimiento facial.
- Vehículos autónomos.

---

## **3. Modelos de Lenguaje Grande (LLM)**

Los **Modelos de Lenguaje Grande** (_Large Language Models_) son una evolución de los modelos de texto.  
Están **entrenados con billones de palabras** y usan arquitecturas de tipo **Transformer**.

**Características principales:**

- Capturan relaciones semánticas complejas entre palabras.
- Pueden razonar, resumir, traducir y mantener coherencia contextual.
- Su desempeño depende del tamaño del modelo (parámetros) y la calidad del entrenamiento.

**Ejemplos:**

- GPT-4, GPT-5 (OpenAI)
- Gemini 1.5 (Google DeepMind)
- Claude 3 (Anthropic)
- Mistral, Falcon, LLaMA

**Fases de entrenamiento de un LLM:**

1. **Pre-entrenamiento:** aprende patrones generales del lenguaje.
2. **Ajuste fino (fine-tuning):** se especializa en tareas específicas.
3. **Instrucción o alineamiento:** se entrena para seguir instrucciones humanas (RLHF).

---

## **4. Difusión (Diffusion Models)**

Los **modelos de difusión** son un tipo de modelo generativo que crea datos (como imágenes) **a partir de ruido**.

**Proceso básico:**

1. Durante el entrenamiento, se añade **ruido progresivo** a una imagen real hasta convertirla en ruido puro.
2. Luego el modelo aprende a **revertir** ese proceso: eliminar el ruido paso a paso hasta recrear o generar una imagen coherente.

**Ejemplo visual simplificado:**

- Entrenamiento: Imagen → + ruido → + más ruido → ruido total.
- Generación: ruido total → – ruido → – ruido → imagen nueva.

**Ejemplos conocidos:**

- Stable Diffusion
- Imagen (Google)
- DALL·E 3 (parte de su arquitectura usa difusión)

**Ventajas:**

- Alta calidad visual.
- Control preciso del estilo y contenido.
- Menor tendencia a producir artefactos o errores.

---

## **5. Transformer**

El **Transformer** es la arquitectura más influyente en la IA moderna.  
Fue introducido en 2017 con el paper _“Attention is All You Need”_.

**Principio clave:**  
En lugar de procesar secuencias palabra por palabra (como las RNN), el Transformer usa **mecanismos de atención** para analizar **toda la secuencia a la vez**, identificando qué partes del texto son más relevantes para cada token.

**Componentes:**

- **Encoder:** analiza y representa la entrada.
- **Decoder:** genera la salida (por ejemplo, una traducción o respuesta).
- **Atención (Self-Attention):** determina la relación entre las palabras del texto.

**Ejemplos de modelos basados en Transformer:**

- GPT (Generative Pretrained Transformer)
- BERT
- T5
- PaLM
- BLOOM

**Ventajas:**

- Escalabilidad con grandes volúmenes de datos.
- Capacidad para entender contexto a largo plazo.
- Versatilidad para texto, imagen, audio o video.

---

## **6. Autoencodificadores Variacionales (VAE)**

Los **Autoencodificadores Variacionales (VAE)** son modelos diseñados para **representar datos complejos en una forma comprimida y continua**.  
Se utilizan tanto para **reducción de dimensionalidad** como para **generación de datos**.

**Funcionamiento:**

1. El **encoder** convierte los datos de entrada en una representación interna (latente).
2. El **decoder** intenta reconstruir los datos originales desde esa representación.
3. A diferencia de un autoencodificador clásico, el VAE introduce **aleatoriedad controlada** (variacional), permitiendo crear nuevas muestras similares.

**Ejemplos de uso:**

- Generación de rostros o voces sintéticas.
- Detección de anomalías.
- Reconstrucción de imágenes ruidosas.

**Ventajas:**

- Capacidad de generar contenido continuo y variado.
- Facilita la exploración del espacio latente.

---

## **7. Redes Generativas Antagónicas (GANs)**

Las **GAN (Generative Adversarial Networks)** son un tipo de red neuronal que enfrenta **dos modelos entre sí**:

- Un **generador**, que intenta crear datos falsos realistas.
- Un **discriminador**, que intenta detectar si los datos son reales o falsos.

Ambos se entrenan de manera competitiva:

- Si el discriminador detecta falsos, el generador mejora.
- Si el generador engaña al discriminador, gana.

Con el tiempo, el generador aprende a **producir datos casi indistinguibles de los reales**.

**Ejemplos:**

- DeepFakes (rostros realistas).
- Creación de arte o moda.
- Mejora de resolución de imágenes.

**Ventajas:**

- Altísima calidad visual.
- Creatividad combinatoria.

**Desventajas:**

- Dificultad para estabilizar el entrenamiento.
- Riesgo de uso indebido (imágenes falsas, desinformación).

---

## **8. Redes Neuronales Convolucionales (CNNs)**

Las **Redes Convolucionales (CNNs)** están diseñadas para **procesar datos con estructura espacial**, especialmente imágenes.  
Usan **filtros (kernels)** que se desplazan sobre la imagen para detectar patrones locales como bordes, texturas o formas.

**Estructura típica:**

1. **Capa convolucional:** aplica filtros a la imagen.
2. **Capa de activación:** introduce no linealidad (por ejemplo, ReLU).
3. **Capa de agrupamiento (pooling):** reduce la dimensión manteniendo información relevante.
4. **Capa densa final:** toma decisiones (clasificación o regresión).

**Ejemplos:**

- Reconocimiento facial (FaceNet).
- Diagnóstico médico (radiografías, tomografías).
- Detección de objetos (YOLO, SSD).

**Ventajas:**

- Gran precisión en visión artificial.
- Capacidad para aprender características automáticamente.

**Limitaciones:**

- Requiere grandes cantidades de datos etiquetados.
- Menor eficacia en tareas no visuales.

---

## **9. Entrenamiento de modelos**

El **entrenamiento** es el proceso mediante el cual una IA **aprende a partir de los datos**.

### Etapas principales:

1. **Recolección de datos:**  
    Los datos se preparan, limpian y etiquetan según la tarea.
2. **Preprocesamiento:**  
    Se normalizan, tokenizan o transforman para ser entendidos por la red.
3. **Entrenamiento:**  
    El modelo ajusta sus **pesos** para minimizar el error (pérdida).
4. **Validación:**  
    Se prueba con datos no vistos para medir rendimiento.
5. **Ajuste fino (Fine-tuning):**  
    Se adapta a tareas o contextos específicos.
6. **Inferencia:**  
    Es la fase en la que el modelo ya entrenado **produce resultados reales** a partir de nuevas entradas.

**Factores que influyen en el rendimiento:**

- Cantidad y calidad de los datos.
- Capacidad de cómputo (GPU, TPU).
- Tamaño y arquitectura del modelo.
- Hiperparámetros y tasa de aprendizaje.

---

## **Conclusión del módulo**

Los procesos internos de la inteligencia artificial moderna se basan en una **combinación de arquitecturas neuronales** y **métodos de entrenamiento**.  
Cada tipo de modelo (difusión, Transformer, GAN, CNN, VAE) aporta soluciones distintas a los retos de la IA generativa.  
Entender su funcionamiento es esencial para avanzar hacia la implementación práctica y el diseño de nuevas aplicaciones basadas en IA.