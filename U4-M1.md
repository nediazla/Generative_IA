# **Módulo 1: Sesgo**

## **Objetivo general del módulo**

Comprender la naturaleza, las causas y las implicaciones del **sesgo en los sistemas de inteligencia artificial generativa**, analizando cómo los datos, los algoritmos y los contextos de uso influyen en la neutralidad o parcialidad de los resultados generados.  
El estudiante será capaz de identificar los principales **tipos de sesgo**, sus orígenes en el entrenamiento y en la interacción con el modelo, así como los mecanismos técnicos y éticos diseñados para **reducir o controlar** dichos sesgos en entornos profesionales.

---

## **Términos clave**

- **Sesgo (Bias):** desviación sistemática en los resultados de un modelo de IA que genera errores, desigualdad o distorsión de la información.
- **Datos de entrenamiento:** conjunto de textos, imágenes o registros con los que un modelo aprende patrones lingüísticos o visuales.
- **Guardrails:** límites o mecanismos de seguridad que restringen la generación de respuestas inapropiadas, discriminatorias o dañinas.
- **Prompt:** instrucción o entrada lingüística que puede inducir o reducir sesgos en la respuesta generada.
- **Equidad algorítmica:** principio que busca que los resultados del modelo sean justos y no discriminatorios.
- **Sesgo cultural:** tendencia del modelo a reproducir perspectivas, valores o jerarquías culturales dominantes en sus datos de entrenamiento.
- **Mitigación del sesgo:** conjunto de estrategias técnicas y éticas destinadas a identificar, medir y corregir distorsiones sistemáticas en la IA.

---

## **1. Sesgo en la IA**

El **sesgo en la inteligencia artificial** es una desviación estructural que produce resultados **parciales, injustos o inexactos**.  
Se manifiesta cuando un sistema generativo favorece sistemáticamente determinadas ideas, grupos, culturas o perspectivas debido a **asimetrías en sus datos o en su diseño**.

### **a) Naturaleza del sesgo**

Los modelos de IA no son neutrales: aprenden de información producida por seres humanos, y esa información contiene **valores, prejuicios y contextos históricos**.  
Por tanto, la IA no crea el sesgo, sino que **lo amplifica o reproduce** en función de cómo fue representado en sus fuentes de entrenamiento.

### **b) Dimensión epistemológica**

Desde el punto de vista teórico, el sesgo representa una **distorsión cognitiva algorítmica**.  
El modelo, al aprender patrones probabilísticos, no distingue entre lo frecuente y lo correcto; generaliza comportamientos del lenguaje o de la sociedad sin juicio moral.  
Así, el sesgo es la **huella estadística de la cultura** en la que la IA fue entrenada.

### **c) Tipos de sesgo en la IA generativa**

- **Sesgo de representación:** exclusión o subrepresentación de ciertos grupos, temas o lenguajes.
- **Sesgo cultural:** predominio de perspectivas occidentales o anglocéntricas.
- **Sesgo de género:** tendencia a asociar profesiones, roles o adjetivos a un género determinado.
- **Sesgo ideológico:** inclinación hacia visiones políticas, morales o religiosas específicas.
- **Sesgo de confirmación:** generación de información alineada con expectativas previas del usuario.

### **d) Implicaciones éticas**

El sesgo algorítmico afecta la **equidad, la inclusión y la confianza** en la IA.  
En contextos educativos, laborales o institucionales, puede generar decisiones injustas o percepciones distorsionadas, por lo que su identificación es un componente esencial de la **responsabilidad tecnológica**.

---

## **2. Datos de entrenamiento**

Los **datos de entrenamiento** son el principal origen del sesgo en los modelos generativos.  
Un modelo aprende patrones lingüísticos, estadísticos y semánticos a partir del conjunto de información con que fue entrenado; si esos datos son parciales o incompletos, el modelo **replicará las mismas limitaciones**.

### **a) Fundamento técnico**

Durante el entrenamiento, el modelo ajusta sus parámetros internos para **predecir la siguiente palabra, píxel o símbolo** en una secuencia.  
La frecuencia de ciertos patrones lingüísticos influye en la probabilidad de que el modelo los reproduzca.  
Por ejemplo, si la mayoría de los textos asocian la palabra “ingeniero” con un pronombre masculino, el modelo tenderá a replicar esa asociación.

### **b) Fuentes del sesgo en los datos**

1. **Desbalance de representación:** ciertos grupos o contextos aparecen en menor proporción.
2. **Datos históricos obsoletos:** perpetúan visiones del pasado que ya no reflejan la diversidad actual.
3. **Lenguaje informal o discriminatorio:** tomado de redes sociales o foros públicos.
4. **Traducciones automáticas defectuosas:** que alteran significados culturales o de género.

### **c) Dimensión epistemológica**

Los datos constituyen la **memoria colectiva del modelo**.  
En ellos no solo se almacena conocimiento, sino también ideología.  
Por tanto, la curaduría de datos debe ser entendida como una **tarea ética y científica**, no meramente técnica.

### **d) Mitigación del sesgo en los datos**

- Ampliación de la diversidad de fuentes.
- Balance de representaciones culturales y lingüísticas.
- Filtrado de contenido ofensivo o discriminatorio.
- Supervisión humana durante la fase de anotación y limpieza.

---

## **3. Guardrails**

Los **guardrails** (o rieles de seguridad) son mecanismos diseñados para **limitar el comportamiento de los modelos de IA**, evitando que generen contenido dañino, sesgado o éticamente inaceptable.  
Constituyen una capa de **control y moderación** sobre el modelo base.

### **a) Función estructural**

Los _guardrails_ se implementan mediante:

- **Filtros de contenido:** bloquean palabras o temas sensibles (violencia, odio, discriminación).
- **Modelos de clasificación complementarios:** analizan la respuesta antes de mostrarla al usuario.
- **Reforzamiento con retroalimentación humana (RLHF):** entrenamiento que ajusta el modelo hacia respuestas seguras y socialmente responsables.
- **Reglas de negación contextual:** el modelo aprende a rechazar peticiones inapropiadas o ilegales.

### **b) Dimensión teórica**

Los _guardrails_ representan la frontera entre **libertad generativa y responsabilidad social**.  
No buscan censurar, sino garantizar que el lenguaje generado se mantenga dentro de límites éticos y legales.  
Desde la filosofía de la tecnología, funcionan como una **traducción algorítmica de la ética normativa**.

### **c) Límites y desafíos**

- Los _guardrails_ pueden **restringir la creatividad** o impedir análisis legítimos si son demasiado estrictos.
- No eliminan el sesgo estructural, solo regulan su manifestación visible.
- Su eficacia depende del equilibrio entre seguridad y libertad de expresión.

---

## **4. Prompts**

Los **prompts**, o instrucciones dadas al modelo, pueden **inducir, amplificar o reducir el sesgo** dependiendo de cómo estén formulados.  
La interacción humana, por tanto, no es neutral: la elección de palabras, tono y contexto afecta directamente el tipo de respuesta que el sistema genera.

### **a) Sesgo inducido por el usuario**

Un _prompt_ que presupone una idea (“Explica por qué los hombres son mejores líderes que las mujeres”) conduce inevitablemente a una respuesta sesgada, ya que la IA **responde dentro del marco que el lenguaje propone**.  
El modelo no corrige el sesgo del enunciado, sino que lo desarrolla lingüísticamente.

### **b) Diseño de prompts éticamente neutros**

- Usar formulaciones abiertas y equilibradas.
- Evitar suposiciones implícitas o valoraciones subjetivas.
- Solicitar análisis desde múltiples perspectivas (“describe ventajas y desventajas de…”).
- Incluir criterios de objetividad o evidencia (“basado en datos verificables…”).

### **c) Dimensión epistemológica**

El _prompt_ es el punto de contacto entre el lenguaje humano y el razonamiento algorítmico.  
En él se proyectan las intenciones, valores y expectativas del usuario.  
Por tanto, el control del sesgo no reside solo en el modelo, sino también en la **intencionalidad comunicativa del interlocutor humano**.

---

## **5. Sesgos comunes**

Los **sesgos comunes** en sistemas de inteligencia artificial generativa se clasifican según su origen y efecto.  
Comprenderlos es esencial para su detección y mitigación.

### **a) Tipología general**

1. **Sesgo de género:**  
    Reproducción de estereotipos tradicionales en la asignación de roles o adjetivos (por ejemplo, asociar “liderazgo” con hombres y “empatía” con mujeres).
2. **Sesgo cultural o lingüístico:**  
    Preferencia por contextos, acentos o expresiones occidentales y angloparlantes; dificultades para interpretar diversidad cultural o regional.
3. **Sesgo racial o étnico:**  
    Representaciones visuales o textuales desproporcionadas, ausencia de minorías o estigmatización.
4. **Sesgo económico o geográfico:**  
    Asumir condiciones de países desarrollados como norma general.
5. **Sesgo ideológico y político:**  
    Priorización de marcos narrativos dominantes o de discursos mayoritarios en medios de comunicación.
6. **Sesgo de confirmación:**  
    Tendencia del modelo a reforzar creencias del usuario en lugar de ofrecer información crítica o contradictoria.    

### **b) Dimensión ética y cognitiva**

Los sesgos comunes no son errores aislados, sino **estructuras de pensamiento probabilístico** heredadas de los datos sociales.  
Desde la teoría de la información, constituyen una forma de **entropía semántica moral**, donde la diversidad del mundo real se reduce a un conjunto limitado de patrones dominantes.  
Por ello, la gestión del sesgo no es solo un problema técnico, sino un **desafío epistemológico y cultural**.

---

## **Conclusión del módulo**

El **sesgo en la inteligencia artificial** no es un accidente, sino una consecuencia inherente de la manera en que los sistemas aprenden del lenguaje humano.  
Su comprensión requiere integrar enfoques técnicos, éticos y filosóficos.  
Los datos, los _guardrails_ y los _prompts_ conforman las tres capas principales de influencia: la información con la que el modelo aprende, las reglas que lo limitan y las instrucciones que recibe.